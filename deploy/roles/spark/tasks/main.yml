---

- name: Push boto config
  template:
    src: boto.cfg.j2
    dest: /etc/boto.cfg

- name: Install boto3, for ec2_instance_facts
  pip:
    name: boto3

- name: Get master facts
  register: master
  ec2_instance_facts:
    region: '{{ ec2_region }}'
    filters:
      instance-state-name: running
      'tag:mit': spark-master

- name: Set master host
  set_fact:
    spark_master_host:
      '{{ master.instances[0].private_dns_name }}'

- name: Set worker count
  set_fact:
    spark_worker_count:
      '{{ groups["tag_mit_spark_worker"] | length }}'

- name: Set worker CPU count
  set_fact:
    spark_worker_vcpus:
      '{{ hostvars[groups["tag_mit_spark_worker"][0]]
      ["ansible_processor_vcpus"] }}'

- name: Create config directory
  file:
    path: /etc/spark
    state: directory

- name: Render configs
  template:
    src: '{{ item }}.j2'
    dest: /etc/spark/{{ item }}
  with_items:
    - spark-defaults.conf
    - spark-env.sh

- name: Log in to Docker Hub
  docker_login:
    username: '{{ docker_username }}'
    password: '{{ docker_password }}'
    email: '{{ docker_email }}'

- name: Start master
  include_tasks: start.yml
  when: '"tag_mit_spark_master" in group_names'
  vars:
    command: spark-class org.apache.spark.deploy.master.Master

- name: Start workers
  include_tasks: start.yml
  when: '"tag_mit_spark_worker" in group_names'
  vars:
    command:
      'spark-class org.apache.spark.deploy.worker.Worker
      {{ spark_master_url }}'
